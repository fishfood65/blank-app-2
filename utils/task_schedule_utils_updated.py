# task_schedule_utils.py

from collections import defaultdict
import pandas as pd
import re
from typing import List, Tuple, Optional
import streamlit as st

def generate_category_keywords_from_labels(input_data):
    keyword_freq = defaultdict(int)
    for section, entries in input_data.items():
        for entry in entries:
            label = entry.get("question", "")
            words = re.findall(r"\b\w{4,}\b", label.lower())
            for word in words:
                keyword_freq[word] += 1
    candidate_keywords = {k: v for k, v in keyword_freq.items() if v >= 2}
    sorted_keywords = sorted(candidate_keywords.items(), key=lambda x: -x[1])
    return sorted_keywords

def filter_tasks(df, category=None, tag=None):
    if df.empty:
        return df
    if category:
        df = df[df["Category"] == category]
    if tag:
        df = df[df["Tag"] == tag]
    return df

def group_tasks_by_tag(df):
    if df.empty:
        return {}
    return dict(tuple(df.groupby("Tag")))

def group_tasks_by_category(df):
    if df.empty:
        return {}
    return dict(tuple(df.groupby("Category")))

def schedule_tasks_from_templates(
    tasks: list,
    valid_dates: list,
    utils: dict,
    debug: bool = False
) -> pd.DataFrame:
    """
    Given a list of task dicts and valid_dates, produce a scheduled DataFrame using known frequency/dates.

    Each task dict must contain:
      - 'question': the label
      - 'answer': the text to parse
      - 'category': task category
      - 'section': original input section (optional)

    Returns:
        pd.DataFrame with: Date, Day, Task, Tag, Category, Area, Source
    """
    if not isinstance(tasks, list):
        raise ValueError("Expected list of task dicts for 'tasks'")
    if not isinstance(valid_dates, list) or not valid_dates:
        raise ValueError("valid_dates must be a non-empty list of datetime.date objects")

    emoji_tags = utils["emoji_tags"]
    weekday_to_int = utils["weekday_to_int"]
    extract_week_interval = utils["extract_week_interval"]
    extract_weekday_mentions = utils["extract_weekday_mentions"]
    extract_dates = utils["extract_dates"]
    normalize_date = utils["normalize_date"]
    determine_frequency_tag = utils["determine_frequency_tag"]

    all_rows = []

    for task in tasks:
        if not isinstance(task, dict):
            continue  # skip invalid task
        label = task.get("question", "")
        answer = str(task.get("answer", "")).strip()
        category = task.get("category", "Uncategorized")
        section = task.get("section", "")
        area = task.get("Area", "home")
        tag = determine_frequency_tag(answer, valid_dates)
        source = section or category

        if not label or not answer:
            continue  # skip empty tasks

        if debug:
            print(f"üîç Scheduling: {label} ‚Üí {tag} | From: {answer[:60]}")

        rows = []

        # One-time dates
        for ds in extract_dates(answer):
            parsed_date = normalize_date(ds)
            if parsed_date and parsed_date in valid_dates:
                rows.append({
                    "Date": str(parsed_date),
                    "Day": parsed_date.strftime("%A"),
                    "Task": f"{label} ‚Äì {answer}",
                    "Tag": emoji_tags.get("[One-Time]", tag),
                    "Category": category,
                    "Source": source,
                    "Area": area
                })

        # Repeating (interval-based)
        interval = extract_week_interval(answer)
        if interval:
            base_date = valid_dates[0]
            for d in valid_dates:
                if (d - base_date).days % (interval * 7) == 0:
                    rows.append({
                        "Date": str(d),
                        "Day": d.strftime("%A"),
                        "Task": f"{label} ‚Äì {answer}",
                        "Tag": f"‚ÜîÔ∏è Every {interval} Weeks",
                        "Category": category,
                        "Source": source,
                        "Area": area
                    })

        # Weekly mentions
        weekday_mentions = extract_weekday_mentions(answer)
        if weekday_mentions and not interval:
            for wd in weekday_mentions:
                weekday_idx = weekday_to_int.get(wd)
                for d in valid_dates:
                    if d.weekday() == weekday_idx:
                        rows.append({
                            "Date": str(d),
                            "Day": d.strftime("%A"),
                            "Task": f"{label} ‚Äì {answer}",
                            "Tag": emoji_tags.get("[Weekly]"),
                            "Category": category,
                            "Source": source,
                            "Area": area
                        })

        # Monthly catch-all
        if "monthly" in answer.lower():
            current_date = pd.to_datetime(valid_dates[0])
            while current_date.date() <= valid_dates[-1]:
                if current_date.date() in valid_dates:
                    rows.append({
                        "Date": str(current_date.date()),
                        "Day": current_date.strftime("%A"),
                        "Task": f"{label} ‚Äì {answer}",
                        "Tag": emoji_tags.get("[Monthly]"),
                        "Category": category,
                        "Source": source,
                        "Area": area
                    })
                current_date += pd.DateOffset(months=1)

        # Fallback: daily if no pattern found
        if not rows:
            for d in valid_dates:
                rows.append({
                    "Date": str(d),
                    "Day": d.strftime("%A"),
                    "Task": f"{label} ‚Äì {answer}",
                    "Tag": emoji_tags.get("[Daily]"),
                    "Category": category,
                    "Source": source,
                    "Area": area
                })

        all_rows.extend(rows)

    return pd.DataFrame(all_rows)

def extract_unscheduled_tasks_from_inputs(section, label_task_fn, valid_dates, utils):
    import streamlit as st
    input_data = st.session_state.get("input_data", {})
    section_data = input_data.get(section, [])
    rows = []
    for item in section_data:
        label = item.get("question")
        answer = item.get("answer")
        if label and answer:
            task_rows = label_task_fn(label, answer, valid_dates, utils)
            rows.extend(task_rows)
    return pd.DataFrame(rows)

def generate_combined_schedule(valid_dates, utils, sections=["Trash Handling", "Mail", "Quality-Oriented Household Services", "Rent or Own"]):
    combined_rows = []
    for section in sections:
        extractor_fn = utils.get(f"extractor_{section.replace(' ', '_').lower()}")
        if extractor_fn:
            df = extractor_fn(valid_dates, utils)
            if not df.empty:
                combined_rows.append(df)
    return pd.concat(combined_rows, ignore_index=True) if combined_rows else pd.DataFrame()

def extract_unscheduled_tasks_from_inputs_with_category(section_key="input_data") -> pd.DataFrame:
    """
    Extracts all captured tasks from input_data across all sections and infers 'category' and 'Area'.
    Returns a flat DataFrame with consistent columns.
    """
    all_rows = []
    input_data = st.session_state.get(section_key, {})

    for section, entries in input_data.items():
        inferred_category = section or "Uncategorized"
        if isinstance(entries, dict):  # Nested format (e.g. "Quality-Oriented Household Services.Cleaning")
            for group_name, group_fields in entries.items():
                if not isinstance(group_fields, dict):
                    continue
                for label, value in group_fields.items():
                    if not value:
                        continue
                    all_rows.append({
                        "question": label,
                        "answer": value,
                        "section": section,
                        "subcategory": group_name,
                        "category": inferred_category,
                        "Area": "home",
                    })

        elif isinstance(entries, list):  # Flat format (e.g. pet or trash)
            for item in entries:
                label = item.get("question")
                value = item.get("answer")
                if not label or not value:
                    continue
                all_rows.append({
                    "question": label,
                    "answer": value,
                    "section": section,
                    "subcategory": None,
                    "category": inferred_category,
                    "Area": "home",
                })

    df = pd.DataFrame(all_rows)

    # Ensure required columns exist, even if empty
    for col in ["question", "answer", "category", "section", "subcategory", "Area"]:
        if col not in df.columns:
            df[col] = None

    return df

def export_schedule_to_markdown(schedule_df: pd.DataFrame, image_base_url: Optional[str] = None) -> str:
    """
    Converts a schedule DataFrame to markdown format with optional image URLs.

    Args:
        schedule_df (pd.DataFrame): Schedule DataFrame.
        image_base_url (str, optional): Base URL to prepend to image filenames, if any.

    Returns:
        str: Markdown string.
    """
    if schedule_df.empty:
        return "_No schedule data available._"

    schedule_df["Date"] = pd.to_datetime(schedule_df["Date"], errors="coerce")
    schedule_df = schedule_df.sort_values(by=["Date", "Source", "Tag", "Task"])
    schedule_df["Day"] = schedule_df["Date"].dt.strftime("%A")
    schedule_df["DateStr"] = schedule_df["Date"].dt.strftime("%Y-%m-%d")

    grouped = schedule_df.groupby("Date")
    lines = []

    for date, group in grouped:
        day_str = date.strftime("%A, %Y-%m-%d")
        lines.append(f"### üìÖ {day_str}\n")
        lines.append("| Task | Image |")
        lines.append("|------|--------|")

        for _, row in group.iterrows():
            task = row["Task"]
            image_md = ""

            # Attempt to extract image reference from task text (if tagged)
            if "üì∑ Image:" in task:
                task, filename = task.split("üì∑ Image:")
                filename = filename.strip()
                if image_base_url:
                    image_md = f"![{filename}]({image_base_url.rstrip('/')}/{filename})"
                else:
                    image_md = f"![{filename}]({filename})"

            lines.append(f"| {task.strip()} | {image_md} |")

        lines.append("")  # blank line for spacing

    return "\n".join(lines)

def get_schedule_utils():
    """Shared date parsing, tag generation, and frequency utilities."""
    print("üí° get_schedule_utils() CALLED")
    emoji_tags = {
        "[Daily]": "üîÅ Daily",
        "[Weekly]": "üìÖ Weekly",
        "[One-Time]": "üóìÔ∏è One-Time",
        "[X-Weeks]": "‚ÜîÔ∏è Every X Weeks",
        "[Monthly]": "üìÜ Monthly"
    }

    weekday_to_int = {
        "Monday": 0, "Tuesday": 1, "Wednesday": 2, "Thursday": 3,
        "Friday": 4, "Saturday": 5, "Sunday": 6
    }

    def extract_week_interval(text):
        text = text.lower()
        print("üß™ Checking interval in text:", text)

        # ‚úÖ Fix: use \d+ correctly, not \\d+
        if "every week" in text and not re.search(r"every \d+ week", text):
            print("‚úÖ Detected 'every week' ‚Üí returning 1")
            return 1

        match = re.search(r"every (\d+) week", text)
        if match:
            print(f"‚úÖ Detected 'every {match.group(1)} weeks'")
            return int(match.group(1))

        if "biweekly" in text:
            return 2

        return None

    def extract_weekday_mentions(text):
        return [day for day in weekday_to_int if day.lower() in text.lower()]

    def extract_dates(text):
        patterns = [
            r"\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\s+\d{1,2}(?:,\s*\d{4})?",
            r"\b\d{1,2}/\d{1,2}(?:/\d{2,4})?"
        ]
        matches = []
        for pattern in patterns:
            matches += re.findall(pattern, text, flags=re.IGNORECASE)
        return matches

    def normalize_date(date_str):
        try:
            return pd.to_datetime(date_str, errors="coerce").date()
        except:
            return None

    def determine_frequency_tag(text, valid_dates):
        interval = extract_week_interval(text)
        weekday_mentions = extract_weekday_mentions(text)

        for ds in extract_dates(text):
            parsed_date = normalize_date(ds)
            if parsed_date and parsed_date in valid_dates:
                return emoji_tags["[One-Time]"]

        if interval:
            return f"‚ÜîÔ∏è Every {interval} Weeks"
        if weekday_mentions and not interval:
            return emoji_tags["[Weekly]"]
        if "monthly" in text.lower():
            return emoji_tags["[Monthly]"]
        return emoji_tags["[Daily]"]

    return {
        "emoji_tags": emoji_tags,
        "weekday_to_int": weekday_to_int,
        "extract_week_interval": extract_week_interval,
        "extract_weekday_mentions": extract_weekday_mentions,
        "extract_dates": extract_dates,
        "normalize_date": normalize_date,
        "determine_frequency_tag": determine_frequency_tag
    }
def generate_flat_home_schedule_markdown(schedule_df):
    """
    Generate a unified markdown schedule grouped by Date ‚Üí Tasks.
    Sets Category to 'home' and adds uploaded image file names next to matching tasks.

    Args:
        schedule_df (pd.DataFrame): Combined schedule (trash + mail).
    Returns:
        str: Markdown string with image file names next to tasks.
    """
    import pandas as pd

    if schedule_df.empty:
        return "_No schedule data available._"

    # Normalize and sort
    schedule_df["Date"] = pd.to_datetime(schedule_df["Date"], errors="coerce")
    schedule_df = schedule_df.sort_values(by=["Date", "Source", "Tag", "Task"])
    schedule_df["Day"] = schedule_df["Date"].dt.strftime("%A")
    schedule_df["DateStr"] = schedule_df["Date"].dt.strftime("%Y-%m-%d")

    # Set category to 'home'
    schedule_df["Category"] = "home"

    # Prepare image label-to-filename map
    image_map = {}
    if "trash_images" in st.session_state:
        for label, image_data in st.session_state["trash_images"].items():
            if image_data:
                # Use uploader file name if available
                uploader_key = f"{label.replace(' Image', '')}_upload"
                file = st.session_state.get(uploader_key)
                if file and hasattr(file, "name"):
                    image_map[label.replace(" Image", "").lower()] = file.name
                else:
                    image_map[label.replace(" Image", "").lower()] = "üì∑ Uploaded"

    # Modify tasks with matching image references
    def append_image_filename(row):
        for label, filename in image_map.items():
            if label in row["Task"].lower():
                return f'{row["Task"]}  \nüì∑ Image: {filename}'
        return row["Task"]

    schedule_df["Task"] = schedule_df.apply(append_image_filename, axis=1)

    # Generate markdown by date
    sections = []
    for date, group in schedule_df.groupby("Date"):
        day = date.strftime("%A")
        date_str = date.strftime("%Y-%m-%d")
        header = f"**üìÖ {day}, {date_str}**"

        table = group[["Task", "Tag", "Category", "Source"]].to_markdown(index=False)
        sections.append(f"{header}\n{table}\n")

    return "\n".join(sections).strip()

def extract_and_schedule_all_tasks(valid_dates: list, utils: dict = None) -> pd.DataFrame:
    """
    Complete pipeline that extracts all captured tasks and schedules them using date templates.
    """
    if utils is None:
        from utils.schedule_utils import get_schedule_utils
        utils = get_schedule_utils()

    # FIX: Ensure it's a list of dicts, not a DataFrame
    raw_df = extract_unscheduled_tasks_from_inputs_with_category()
    raw_tasks = raw_df.to_dict(orient="records")

    return schedule_tasks_from_templates(raw_tasks, valid_dates, utils)

